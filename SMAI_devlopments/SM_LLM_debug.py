import pandas as pd
from datetime import datetime
import time
import re
from sentence_transformers import SentenceTransformer, util
from kiwipiepy import Kiwi
from SynonymPattern import SynonymManager

class AcademicCalendarRAG:
    def __init__(self, csv_path='hagsailjeong.csv'):
        self.synonym_mgr = SynonymManager()
        self._wait_for_synonyms()
        self.term_db = self.synonym_mgr.get_synonyms()
        self.synonym_map = {term: data['synonyms'] for term, data in self.term_db.items()}
        self.negative_map = {term: data['negatives'] for term, data in self.term_db.items()}
        self.df = self._load_data(csv_path)
        self.model = SentenceTransformer('distiluse-base-multilingual-cased-v1')
        self.kiwi = Kiwi()
        self._prepare_embeddings()
        self.current_date = pd.Timestamp(datetime.today().date())
        print(f"ì´ˆê¸°í™” ì™„ë£Œ - í˜„ì¬ ë‚ ì§œ: {self.current_date}")

    def _wait_for_synonyms(self):
        retry_count = 0
        while not self.synonym_mgr.synonym_path.exists():
            if retry_count == 0:
                print("ë™ì˜ì–´ ì‚¬ì „ ìƒì„± ì¤‘... (ìµœëŒ€ 2ë¶„ ì†Œìš”)")
                self.synonym_mgr._generate_terms()
            if retry_count >= 12:
                raise FileNotFoundError("ë™ì˜ì–´ ì‚¬ì „ ìƒì„± ì‹¤íŒ¨")
            time.sleep(10)
            retry_count += 1
        print("ë™ì˜ì–´ ì‚¬ì „ ë¡œë“œ ì™„ë£Œ\n")

    def _load_data(self, csv_path):
        df = pd.read_csv(csv_path)
        df['Start'] = pd.to_datetime(df['Start'])
        df['End'] = pd.to_datetime(df['End'])
        current_date = pd.Timestamp(datetime.today().date())
        df = df[df['Start'].dt.year >= current_date.year]
        df['document'] = df['Title']
        print(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ - {len(df)}ê°œì˜ í•­ëª©")
        return df

    def _prepare_embeddings(self):
        self.document_embeddings = self.model.encode(
            self.df['document'].tolist(),
            convert_to_tensor=True,
            show_progress_bar=True
        )
        print("ì„ë² ë”© ì¤€ë¹„ ì™„ë£Œ")

    def _extract_keywords(self, query):
        tokens = self.kiwi.tokenize(query)
        keywords = [token.form for token in tokens if token.tag.startswith('NN')] or [query]
        print(f"ì¶”ì¶œëœ í‚¤ì›Œë“œ: {keywords}")
        return keywords

    def _get_relevant_documents(self, query, top_k=10, similarity_threshold=0.3):
        print(f"\n=== ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì‘: '{query}' ===")
        query_keywords = self._extract_keywords(query)
        q_lower = query.lower().replace(" ", "")
        print(f"ì†Œë¬¸ì ë³€í™˜ ì§ˆë¬¸: {q_lower}")
        query_key = " ".join(query_keywords)
        print(f"ì¿¼ë¦¬ í‚¤: {query_key}")
        print(f"ë™ì˜ì–´: {self.synonym_map.get(query_key, [])}")
        print(f"ë°°ì œì–´: {self.negative_map.get(query_key, [])}")

        query_embedding = self.model.encode(query, convert_to_tensor=True)
        similarities = util.cos_sim(query_embedding, self.document_embeddings)[0].cpu().numpy()
        print(f"ì´ˆê¸° ìœ ì‚¬ë„ ê³„ì‚° ì™„ë£Œ - {len(similarities)}ê°œ ë¬¸ì„œ")

        for i in range(len(similarities)):
            title = self.df.iloc[i]['Title'].lower().replace(" ", "")
            original_similarity = similarities[i]
            print(f"\në¬¸ì„œ {i}: {self.df.iloc[i]['Title']}")
            print(f"  ì´ˆê¸° ìœ ì‚¬ë„: {original_similarity:.4f}")

            exact_match = any(kw.lower() == title for kw in query_keywords)
            synonym_match = any(syn in title for syn in self.synonym_map.get(query_key, []))
            keyword_match = any(kw in title for kw in query_keywords)
            negative_terms = self.negative_map.get(query_key, [])
            negative_match = any(nt in title for nt in negative_terms) and 'ìˆ˜ê°•ì‹ ì²­' in q_lower
            basket_confusion = "ì¥ë°”êµ¬ë‹ˆ" in title and "ìˆ˜ê°•ì‹ ì²­" in q_lower

            if exact_match:
                similarities[i] *= 2.0
                print(f"  ì •í™• ë§¤ì¹­ ì ìš© (Ã—2.0): {similarities[i]:.4f}")
            elif synonym_match:
                similarities[i] *= 1.5
                print(f"  ë™ì˜ì–´ ë§¤ì¹­ ì ìš© (Ã—1.5): {similarities[i]:.4f}")
            elif keyword_match:
                similarities[i] *= 1.2
                print(f"  í‚¤ì›Œë“œ í¬í•¨ ì ìš© (Ã—1.2): {similarities[i]:.4f}")
            if negative_match:
                similarities[i] *= 0.3
                print(f"  ë°°ì œì–´ íŒ¨ë„í‹° ì ìš© (Ã—0.3): {similarities[i]:.4f}")
            elif basket_confusion:
                similarities[i] *= 0.5
                print(f"  ì¥ë°”êµ¬ë‹ˆ í˜¼ë™ íŒ¨ë„í‹° ì ìš© (Ã—0.5): {similarities[i]:.4f}")

            current_month = self.current_date.month
            if "1í•™ê¸°" in self.df.iloc[i]['Title'] and 2 <= current_month <= 7:
                similarities[i] *= 1.02
                print(f"  1í•™ê¸° ê°€ì¤‘ì¹˜ ì ìš© (Ã—1.02, {current_month}ì›”): {similarities[i]:.4f}")
            elif "2í•™ê¸°" in self.df.iloc[i]['Title'] and (8 <= current_month <= 12 or current_month == 1):
                similarities[i] *= 1.02
                print(f"  2í•™ê¸° ê°€ì¤‘ì¹˜ ì ìš© (Ã—1.02, {current_month}ì›”): {similarities[i]:.4f}")

            print(f"  ìµœì¢… ìœ ì‚¬ë„: {similarities[i]:.4f}")

        top_indices = similarities.argsort()[-top_k:][::-1]
        print(f"\nìƒìœ„ {top_k}ê°œ ì¸ë±ìŠ¤: {top_indices}")
        print(f"ìƒìœ„ ìœ ì‚¬ë„: {[f'{similarities[idx]:.4f}' for idx in top_indices]}")
        relevant_docs = self.df.iloc[top_indices]
        filtered_docs = relevant_docs[similarities[top_indices] > similarity_threshold]
        print(f"í•„í„°ë§ëœ ë¬¸ì„œ ìˆ˜: {len(filtered_docs)} (ì„ê³„ê°’: {similarity_threshold})")
        for _, row in filtered_docs.iterrows():
            print(f"  - {row['Title']} (ìœ ì‚¬ë„: {similarities[top_indices[list(relevant_docs.index).index(row.name)]]:.4f})")
        print("=== ì§ˆë¬¸ ì²˜ë¦¬ ì¢…ë£Œ ===\n")
        return filtered_docs if not filtered_docs.empty else pd.DataFrame()

    def _extract_semester(self, events):
        if events.empty:
            return None
        closest_event = events.loc[(events['Start'] - self.current_date).abs().idxmin()]
        start_year = closest_event['Start'].year
        if re.search(r'\d-í•™ê¸°', closest_event['Title']):
            semester = f"{start_year}-{re.search(r'\d-í•™ê¸°', closest_event['Title']).group()}"
        else:
            semester = f"{start_year}-{'1' if closest_event['Start'].month <= 6 else '2'}í•™ê¸°"
        print(f"ì¶”ì¶œëœ í•™ê¸°: {semester}")
        return semester

    def _format_response(self, events, query):
        response = ["ì•ˆë…•í•˜ì„¸ìš”! ê´€ë ¨ í•™ì‚¬ì¼ì • ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤.\n"]
        semester = self._extract_semester(events)
        if semester:
            events = events[events['Title'].str.contains(semester, na=False)]
            print(f"í•™ê¸° í•„í„°ë§ ì ìš©: {semester}")

        # ì§„í–‰ ì¤‘: í˜„ì¬ ë‚ ì§œê°€ Startì™€ End ì‚¬ì´ì— í¬í•¨
        ongoing = events[(events['Start'] <= self.current_date) & (self.current_date <= events['End'])]
        # ê³¼ê±°: ì¢…ë£Œì¼ì´ í˜„ì¬ ë‚ ì§œë³´ë‹¤ ì´ì „
        past = events[events['End'] < self.current_date]
        # ë¯¸ë˜: ì‹œì‘ì¼ì´ í˜„ì¬ ë‚ ì§œë³´ë‹¤ ì´í›„
        future = events[events['Start'] > self.current_date]

        if not ongoing.empty:
            response.append("### ì§„í–‰ ì¤‘ì¸ ì¼ì •")
            for _, row in ongoing.iterrows():
                response.append(
                    f"- ğŸ’¡ {row['Title']}\n"
                    f" â–¸ ê¸°ê°„: {row['Start'].date()} ~ {row['End'].date()}\n"
                    f" â–¸ ìƒíƒœ: ì§„í–‰ ì¤‘\n"
                )

        if not past.empty:
            response.append("### ê³¼ê±° ì¼ì •")
            for _, row in past.iterrows():
                days_passed = (self.current_date - row['End']).days
                response.append(
                    f"- ğŸ”´ {row['Title']}\n"
                    f" â–¸ ê¸°ê°„: {row['Start'].date()} ~ {row['End'].date()}\n"
                    f" â–¸ ìƒíƒœ: ì¢…ë£Œ (D+{days_passed})\n"
                )

        if not future.empty:
            response.append("### ë¯¸ë˜ ì¼ì •")
            sorted_future = future.sort_values('Start')
            # ì§„í–‰ ì¤‘ì¸ ì¼ì •ì´ ìˆìœ¼ë©´ ğŸ’¡ ì‚¬ìš© ì•ˆ í•¨
            use_highlight = ongoing.empty
            for i, (_, row) in enumerate(sorted_future.iterrows()):
                days_remaining = (row['Start'] - self.current_date).days
                icon = "ğŸ’¡" if use_highlight and i == 0 else "ğŸŸ¢"
                response.append(
                    f"- {icon} {row['Title']}\n"
                    f" â–¸ ê¸°ê°„: {row['Start'].date()} ~ {row['End'].date()}\n"
                    f" â–¸ ìƒíƒœ: D-{days_remaining} ì˜ˆì •\n"
                )

        response.append("\nâ€» ì •í™•í•œ ì •ë³´ëŠ” í•™ì‚¬ìš´ì˜íŒ€(ğŸ“ 02-2287-7077)ìœ¼ë¡œ ë¬¸ì˜ ë°”ëë‹ˆë‹¤.")
        return "\n".join(response)

    def get_answer(self, question):
        results = self._get_relevant_documents(question)
        return self._format_response(results, question) if not results.empty else (
            f"âš ï¸ '{question}' ê´€ë ¨ ì¼ì •ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n"
            f"ì˜¤íƒ€ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ ì£¼ì‹œê±°ë‚˜ ìì„¸í•œ ì‚¬í•­ì€ í•™ì‚¬ìš´ì˜íŒ€(â˜ 02-2287-7077)ìœ¼ë¡œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”."
        )

    def main(self):
        print("\nğŸ” í•™ì‚¬ì¼ì • ì¡°íšŒ ì‹œìŠ¤í…œ ì‘ë™ ì¤‘...")
        while True:
            query = input("\nì§ˆë¬¸ (ì¢…ë£Œ: quit): ")
            if query.lower() in ['quit', 'exit']:
                break
            start = time.time()
            print(f"\n{self.get_answer(query)}")
            print(f"\nâ±ï¸ ì²˜ë¦¬ ì‹œê°„: {time.time() - start:.2f}ì´ˆ")

if __name__ == "__main__":
    AcademicCalendarRAG().main()